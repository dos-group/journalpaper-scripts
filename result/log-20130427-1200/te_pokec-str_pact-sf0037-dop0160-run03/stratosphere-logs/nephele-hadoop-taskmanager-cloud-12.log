23:29:41,603 WARN  eu.stratosphere.nephele.configuration.GlobalConfiguration     - Cannot load configuration: unknown element plugins
23:29:41,639 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Reading location of job manager from configuration
23:29:41,650 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Determined address of job manager to be cloud-11.dima.tu-berlin.de/130.149.21.15:6002
23:29:41,660 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Announcing connection information cloud-12 to job manager
23:29:41,728 INFO  eu.stratosphere.nephele.ipc.Server                            - IPC Server Responder: starting
23:29:41,728 INFO  eu.stratosphere.nephele.ipc.Server                            - IPC Server listener on 6122: starting
23:29:41,729 INFO  eu.stratosphere.nephele.ipc.Server                            - IPC Server handler 0 on 6122: starting
23:29:42,827 INFO  eu.stratosphere.nephele.taskmanager.bufferprovider.GlobalBufferPool  - Initialized global buffer pool with 32768 buffers with a size 32768 bytes each
23:29:42,847 INFO  eu.stratosphere.nephele.taskmanager.bytebuffered.ByteBufferedChannelManager  - Initialized byte buffered channel manager with sender-side spilling disabled
23:29:42,858 INFO  eu.stratosphere.nephele.instance.HardwareDescriptionFactory   - Found Tenured Gen pool (max: 24051843072, used: 0)
23:29:42,858 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Initializing memory manager with 22528 megabytes of memory
23:30:18,772 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Build Triads (7/20)
23:30:18,775 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Build Triads (7/20)
23:30:20,902 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (51/160)
23:30:20,903 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (51/160)
23:30:20,904 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (51/160)
23:30:20,906 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (51/160)
23:30:21,649 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (52/160)
23:30:21,649 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (52/160)
23:30:21,651 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (52/160)
23:30:21,652 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (52/160)
23:30:22,465 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (53/160)
23:30:22,466 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (53/160)
23:30:22,468 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (53/160)
23:30:22,468 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (53/160)
23:30:22,753 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (55/160)
23:30:22,753 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (55/160)
23:30:22,755 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (55/160)
23:30:22,756 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (55/160)
23:30:23,571 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (54/160)
23:30:23,571 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (54/160)
23:30:23,573 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (54/160)
23:30:23,575 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (54/160)
23:30:24,275 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (49/160)
23:30:24,276 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (49/160)
23:30:24,278 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (49/160)
23:30:24,279 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (49/160)
23:30:24,646 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (56/160)
23:30:24,646 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (56/160)
23:30:24,648 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (56/160)
23:30:24,649 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (56/160)
23:30:25,442 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (50/160)
23:30:25,442 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (50/160)
23:30:25,444 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (50/160)
23:30:25,445 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (50/160)
23:31:02,574 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Finished PACT code.: Build Triads (7/20)
23:31:02,574 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from RUNNING to FINISHING for task Build Triads (7/20)
23:34:48,583 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_8128934283748044973_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51285 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:34:48,584 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_8128934283748044973_1565 bad datanode[0] 130.149.21.16:45020
23:34:48,585 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_8128934283748044973_1565 in pipeline 130.149.21.16:45020, 130.149.21.22:45020, 130.149.21.26:45020: bad datanode 130.149.21.16:45020
23:34:55,550 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-7822580464689729100_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51287 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:34:55,551 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-7822580464689729100_1565 bad datanode[0] 130.149.21.16:45020
23:34:55,552 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-7822580464689729100_1565 in pipeline 130.149.21.16:45020, 130.149.21.60:45020, 130.149.21.33:45020: bad datanode 130.149.21.16:45020
23:34:59,047 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-5083623947488488592_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51290 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:34:59,049 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5083623947488488592_1565 bad datanode[0] 130.149.21.16:45020
23:34:59,049 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5083623947488488592_1565 in pipeline 130.149.21.16:45020, 130.149.21.23:45020, 130.149.21.2:45020: bad datanode 130.149.21.16:45020
23:35:00,651 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_748840845446188102_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51282 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:35:00,652 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_748840845446188102_1565 bad datanode[0] 130.149.21.16:45020
23:35:00,653 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_748840845446188102_1565 in pipeline 130.149.21.16:45020, 130.149.21.61:45020, 130.149.21.17:45020: bad datanode 130.149.21.16:45020
23:35:03,594 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_6054810775476071700_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51276 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:35:03,594 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6054810775476071700_1565 bad datanode[0] 130.149.21.16:45020
23:35:03,595 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6054810775476071700_1565 in pipeline 130.149.21.16:45020, 130.149.21.3:45020, 130.149.21.61:45020: bad datanode 130.149.21.16:45020
23:35:04,588 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-8554149227619640396_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51292 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:35:04,589 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-8554149227619640396_1565 bad datanode[0] 130.149.21.16:45020
23:35:04,590 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-8554149227619640396_1565 in pipeline 130.149.21.16:45020, 130.149.21.19:45020, 130.149.21.28:45020: bad datanode 130.149.21.16:45020
23:35:05,225 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_518936839281369425_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51279 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:35:05,226 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_518936839281369425_1565 bad datanode[0] 130.149.21.16:45020
23:35:05,227 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_518936839281369425_1565 in pipeline 130.149.21.16:45020, 130.149.21.19:45020, 130.149.21.27:45020: bad datanode 130.149.21.16:45020
23:35:05,295 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_7055582426767472182_1565java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:51273 remote=/130.149.21.16:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:35:05,296 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_7055582426767472182_1565 bad datanode[0] 130.149.21.16:45020
23:35:05,296 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_7055582426767472182_1565 in pipeline 130.149.21.16:45020, 130.149.21.20:45020, 130.149.21.19:45020: bad datanode 130.149.21.16:45020
23:35:54,638 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_8128934283748044973_1590java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:40372 remote=/130.149.21.22:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:35:54,640 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_8128934283748044973_1590 bad datanode[0] 130.149.21.22:45020
23:35:54,640 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_8128934283748044973_1590 in pipeline 130.149.21.22:45020, 130.149.21.26:45020: bad datanode 130.149.21.22:45020
23:36:01,597 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-7822580464689729100_1601java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:48810 remote=/130.149.21.60:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:36:01,598 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-7822580464689729100_1601 bad datanode[0] 130.149.21.60:45020
23:36:01,599 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-7822580464689729100_1601 in pipeline 130.149.21.60:45020, 130.149.21.33:45020: bad datanode 130.149.21.60:45020
23:36:05,085 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-5083623947488488592_1612java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:40605 remote=/130.149.21.23:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:36:05,086 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5083623947488488592_1612 bad datanode[0] 130.149.21.23:45020
23:36:05,086 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5083623947488488592_1612 in pipeline 130.149.21.23:45020, 130.149.21.2:45020: bad datanode 130.149.21.23:45020
23:36:06,692 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_748840845446188102_1620java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:40259 remote=/130.149.21.61:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:36:06,693 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_748840845446188102_1620 bad datanode[0] 130.149.21.61:45020
23:36:06,694 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_748840845446188102_1620 in pipeline 130.149.21.61:45020, 130.149.21.17:45020: bad datanode 130.149.21.61:45020
23:36:09,694 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_6054810775476071700_1635java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:34761 remote=/130.149.21.3:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:36:09,696 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6054810775476071700_1635 bad datanode[0] 130.149.21.3:45020
23:36:09,696 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6054810775476071700_1635 in pipeline 130.149.21.3:45020, 130.149.21.61:45020: bad datanode 130.149.21.3:45020
23:36:10,638 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-8554149227619640396_1641java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:42678 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:36:10,639 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-8554149227619640396_1641 bad datanode[0] 130.149.21.19:45020
23:36:10,640 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-8554149227619640396_1641 in pipeline 130.149.21.19:45020, 130.149.21.28:45020: bad datanode 130.149.21.19:45020
23:36:11,314 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_518936839281369425_1644java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:42680 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:36:11,315 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_518936839281369425_1644 bad datanode[0] 130.149.21.19:45020
23:36:11,316 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_518936839281369425_1644 in pipeline 130.149.21.19:45020, 130.149.21.27:45020: bad datanode 130.149.21.19:45020
23:36:11,396 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_7055582426767472182_1645java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.16:60527 remote=/130.149.21.20:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:36:11,397 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_7055582426767472182_1645 bad datanode[0] 130.149.21.20:45020
23:36:11,397 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_7055582426767472182_1645 in pipeline 130.149.21.20:45020, 130.149.21.19:45020: bad datanode 130.149.21.20:45020
