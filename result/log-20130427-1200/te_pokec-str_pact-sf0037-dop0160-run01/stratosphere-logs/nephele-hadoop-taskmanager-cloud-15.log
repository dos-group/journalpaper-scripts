23:21:11,481 WARN  eu.stratosphere.nephele.configuration.GlobalConfiguration     - Cannot load configuration: unknown element plugins
23:21:11,518 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Reading location of job manager from configuration
23:21:11,529 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Determined address of job manager to be cloud-11.dima.tu-berlin.de/130.149.21.15:6002
23:21:11,539 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Announcing connection information cloud-15 to job manager
23:21:11,608 INFO  eu.stratosphere.nephele.ipc.Server                            - IPC Server Responder: starting
23:21:11,609 INFO  eu.stratosphere.nephele.ipc.Server                            - IPC Server listener on 6122: starting
23:21:11,610 INFO  eu.stratosphere.nephele.ipc.Server                            - IPC Server handler 0 on 6122: starting
23:21:12,729 INFO  eu.stratosphere.nephele.taskmanager.bufferprovider.GlobalBufferPool  - Initialized global buffer pool with 32768 buffers with a size 32768 bytes each
23:21:12,749 INFO  eu.stratosphere.nephele.taskmanager.bytebuffered.ByteBufferedChannelManager  - Initialized byte buffered channel manager with sender-side spilling disabled
23:21:12,760 INFO  eu.stratosphere.nephele.instance.HardwareDescriptionFactory   - Found Tenured Gen pool (max: 24051843072, used: 0)
23:21:12,760 INFO  eu.stratosphere.nephele.taskmanager.TaskManager               - Initializing memory manager with 22528 megabytes of memory
23:21:47,023 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Build Triads (6/20)
23:21:47,027 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Build Triads (6/20)
23:21:50,250 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (47/160)
23:21:50,251 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (47/160)
23:21:50,253 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (47/160)
23:21:50,254 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (47/160)
23:21:50,841 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (42/160)
23:21:50,841 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (42/160)
23:21:50,846 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (42/160)
23:21:50,847 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (42/160)
23:21:51,270 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (44/160)
23:21:51,270 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (44/160)
23:21:51,272 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (44/160)
23:21:51,274 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (44/160)
23:21:51,298 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (43/160)
23:21:51,298 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (43/160)
23:21:51,300 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (43/160)
23:21:51,301 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (43/160)
23:21:51,689 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (45/160)
23:21:51,689 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (45/160)
23:21:51,690 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (45/160)
23:21:51,691 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (45/160)
23:21:52,290 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (46/160)
23:21:52,290 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (46/160)
23:21:52,292 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (46/160)
23:21:52,293 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (46/160)
23:21:52,615 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (41/160)
23:21:52,616 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (41/160)
23:21:52,617 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (41/160)
23:21:52,618 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (41/160)
23:21:54,052 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Close Triads (48/160)
23:21:54,052 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from STARTING to RUNNING for task Triangles (48/160)
23:21:54,054 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Start PACT code.: Close Triads (48/160)
23:21:54,055 INFO  eu.stratosphere.pact.runtime.task.DataSinkTask                - Start PACT code: Triangles (48/160)
23:24:48,687 INFO  eu.stratosphere.pact.runtime.task.RegularPactTask             - Finished PACT code.: Build Triads (6/20)
23:24:48,687 INFO  eu.stratosphere.nephele.execution.ExecutionStateTransition    - TM: ExecutionState set from RUNNING to FINISHING for task Build Triads (6/20)
23:25:53,748 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_3321556165509720616_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35368 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:25:53,749 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3321556165509720616_1161 bad datanode[0] 130.149.21.19:45020
23:25:53,750 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3321556165509720616_1161 in pipeline 130.149.21.19:45020, 130.149.21.30:45020, 130.149.21.24:45020: bad datanode 130.149.21.19:45020
23:25:57,780 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_4776242643705671091_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35370 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:25:57,781 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_4776242643705671091_1161 bad datanode[0] 130.149.21.19:45020
23:25:57,781 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_4776242643705671091_1161 in pipeline 130.149.21.19:45020, 130.149.21.23:45020, 130.149.21.22:45020: bad datanode 130.149.21.19:45020
23:26:00,738 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-2508779501265835882_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35360 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:26:00,739 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-2508779501265835882_1161 bad datanode[0] 130.149.21.19:45020
23:26:00,740 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-2508779501265835882_1161 in pipeline 130.149.21.19:45020, 130.149.21.29:45020, 130.149.21.25:45020: bad datanode 130.149.21.19:45020
23:26:03,227 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-5610421315484696313_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35375 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:26:03,228 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5610421315484696313_1161 bad datanode[0] 130.149.21.19:45020
23:26:03,229 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5610421315484696313_1161 in pipeline 130.149.21.19:45020, 130.149.21.61:45020, 130.149.21.28:45020: bad datanode 130.149.21.19:45020
23:26:08,846 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_6466073581741827404_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35378 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:26:08,847 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6466073581741827404_1161 bad datanode[0] 130.149.21.19:45020
23:26:08,848 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6466073581741827404_1161 in pipeline 130.149.21.19:45020, 130.149.21.33:45020, 130.149.21.21:45020: bad datanode 130.149.21.19:45020
23:26:10,273 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_3241278443036356588_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35361 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:26:10,274 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3241278443036356588_1161 bad datanode[0] 130.149.21.19:45020
23:26:10,275 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3241278443036356588_1161 in pipeline 130.149.21.19:45020, 130.149.21.23:45020, 130.149.21.29:45020: bad datanode 130.149.21.19:45020
23:26:11,445 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-6008391482691613902_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35372 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:26:11,446 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-6008391482691613902_1161 bad datanode[0] 130.149.21.19:45020
23:26:11,447 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-6008391482691613902_1161 in pipeline 130.149.21.19:45020, 130.149.21.33:45020, 130.149.21.21:45020: bad datanode 130.149.21.19:45020
23:26:11,878 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-4935828198585662294_1161java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:35365 remote=/130.149.21.19:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:26:11,879 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-4935828198585662294_1161 bad datanode[0] 130.149.21.19:45020
23:26:11,879 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-4935828198585662294_1161 in pipeline 130.149.21.19:45020, 130.149.21.23:45020, 130.149.21.16:45020: bad datanode 130.149.21.19:45020
23:26:59,943 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_3321556165509720616_1162java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:42898 remote=/130.149.21.30:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:26:59,944 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3321556165509720616_1162 bad datanode[0] 130.149.21.30:45020
23:26:59,945 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3321556165509720616_1162 in pipeline 130.149.21.30:45020, 130.149.21.24:45020: bad datanode 130.149.21.30:45020
23:27:03,878 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_4776242643705671091_1187java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:45947 remote=/130.149.21.23:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:27:03,880 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_4776242643705671091_1187 bad datanode[0] 130.149.21.23:45020
23:27:03,880 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_4776242643705671091_1187 in pipeline 130.149.21.23:45020, 130.149.21.22:45020: bad datanode 130.149.21.23:45020
23:27:06,866 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-2508779501265835882_1206java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:50610 remote=/130.149.21.29:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:27:06,868 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-2508779501265835882_1206 bad datanode[0] 130.149.21.29:45020
23:27:06,868 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-2508779501265835882_1206 in pipeline 130.149.21.29:45020, 130.149.21.25:45020: bad datanode 130.149.21.29:45020
23:27:09,326 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-5610421315484696313_1214java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:41925 remote=/130.149.21.61:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:27:09,327 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5610421315484696313_1214 bad datanode[0] 130.149.21.61:45020
23:27:09,328 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-5610421315484696313_1214 in pipeline 130.149.21.61:45020, 130.149.21.28:45020: bad datanode 130.149.21.61:45020
23:27:14,945 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_6466073581741827404_1243java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:50020 remote=/130.149.21.33:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:27:14,946 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6466073581741827404_1243 bad datanode[0] 130.149.21.33:45020
23:27:14,947 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_6466073581741827404_1243 in pipeline 130.149.21.33:45020, 130.149.21.21:45020: bad datanode 130.149.21.33:45020
23:27:16,379 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_3241278443036356588_1251java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:45960 remote=/130.149.21.23:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:27:16,380 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3241278443036356588_1251 bad datanode[0] 130.149.21.23:45020
23:27:16,381 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_3241278443036356588_1251 in pipeline 130.149.21.23:45020, 130.149.21.29:45020: bad datanode 130.149.21.23:45020
23:27:17,544 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-6008391482691613902_1259java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:50029 remote=/130.149.21.33:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:27:17,545 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-6008391482691613902_1259 bad datanode[0] 130.149.21.33:45020
23:27:17,545 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-6008391482691613902_1259 in pipeline 130.149.21.33:45020, 130.149.21.21:45020: bad datanode 130.149.21.33:45020
23:27:17,978 WARN  org.apache.hadoop.hdfs.DFSClient                              - DFSOutputStream ResponseProcessor exception  for block blk_-4935828198585662294_1261java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/130.149.21.19:45967 remote=/130.149.21.23:45020]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2582)

23:27:17,979 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-4935828198585662294_1261 bad datanode[0] 130.149.21.23:45020
23:27:17,980 WARN  org.apache.hadoop.hdfs.DFSClient                              - Error Recovery for block blk_-4935828198585662294_1261 in pipeline 130.149.21.23:45020, 130.149.21.16:45020: bad datanode 130.149.21.23:45020
